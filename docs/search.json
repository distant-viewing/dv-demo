[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Distant Viewing Guidebook",
    "section": "",
    "text": "Welcome!\nThis is a book.\n\n\n\n\nAchiam, Josh, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, et al. 2023. “GPT-4 Technical Report.” arXiv Preprint arXiv:2303.08774.\n\n\nAdnan, Myasar Mundher, Mohd Shafry Mohd Rahim, Amjad Rehman, Zahid Mehmood, Tanzila Saba, and Rizwan Ali Naqvi. 2021. “Automatic Image Annotation Based on Deep Learning Models: A Systematic Review and Future Challenges.” IEEE Access 9: 50253–64.\n\n\nAfzal, Shehzad, Sohaib Ghani, Mohamad Mazen Hittawe, Sheikh Faisal Rashid, Omar M Knio, Markus Hadwiger, and Ibrahim Hoteit. 2023. “Visualization and Visual Analytics Approaches for Image and Video Datasets: A Survey.” ACM Transactions on Interactive Intelligent Systems 13 (1): 1–41.\n\n\nAnitha Kumari, K, C Mouneeshwari, RB Udhaya, and R Jasmitha. 2020. “Automated Image Captioning for flickr8k Dataset.” In Proceedings of International Conference on Artificial Intelligence, Smart Grid and Smart City Applications: AISGSC 2019, 679–87. Springer.\n\n\nArchives, United States National. n.d. “DOCUMERICA: The Environmental Protection Agency’s Program to Photographically Document Subjects of Environmental Concern, 1972–1977.” https://catalog.archives.gov/id/542493.\n\n\nArnold, Taylor, and Lauren Tilton. 2019. “Distant Viewing: Analyzing Large Visual Corpora.” Digital Scholarship in the Humanities 34 (Supplement_1): i3–16.\n\n\n———. 2020. “Distant Viewing Toolkit: A Python Package for the Analysis of Visual Culture.” Journal of Open Source Software 5 (45): 1800.\n\n\n———. 2023. Distant Viewing: Computational Exploration of Digital Images. MIT Press.\n\n\nChen, Hailin, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shafiq Joty. 2023. “ChatGPT’s One-Year Anniversary: Are Open-Source Large Language Models Catching Up?” arXiv Preprint arXiv:2311.16989.\n\n\nColeman, Catherine Nicole. 2020. “Managing Bias When Library Collections Become Data.” International Journal of Librarianship 5 (1): 8–19.\n\n\nCuntz, Alexander, Paul J Heald, and Matthias Sahli. 2023. “Digitization and Availability of Artworks in Online Museum Collections.” World Intellectual Property Organization (WIPO) Economic Research Working Paper Series, no. 75.\n\n\nDeal, Laura. 2015. “Visualizing Digital Collections.” Technical Services Quarterly 32 (1): 14–34.\n\n\nDemiralp, Çagatay, Carlos E Scheidegger, Gordon L Kindlmann, David H Laidlaw, and Jeffrey Heer. 2014. “Visual Embedding: A Model for Visualization.” IEEE Computer Graphics and Applications 34 (1): 10–15.\n\n\nDi Lenardo, Isabella, Benoı̂t Laurent Auguste Seguin, and Frédéric Kaplan. 2016. “Visual Patterns Discovery in Large Databases of Paintings.” In Digital Humanities 2016.\n\n\nDı́az-Rodrı́guez, Natalia, and Galena Pisoni. 2020. “Accessible Cultural Heritage Through Explainable Artificial Intelligence.” In Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization, 317–24.\n\n\nFlueckiger, Barbara, and Gaudenz Halter. 2020. “Methods and Advanced Tools for the Analysis of Film Colors in Digital Humanities.” DHQ: Digital Humanities Quarterly 14 (4).\n\n\nFraser, Kathleen C, Svetlana Kiritchenko, and Isar Nejadgholi. 2023. “A Friendly Face: Do Text-to-Image Systems Rely on Stereotypes When the Input Is Under-Specified?” arXiv Preprint arXiv:2302.07159.\n\n\nGefen, Alexandre, Léa Saint-Raymond, and Tommaso Venturini. 2021. “AI for Digital Humanities and Computational Social Sciences.” Reflections on Artificial Intelligence for Humanity, 191–202.\n\n\nHiippala, Tuomo, and John A Bateman. 2022. “Semiotically-Grounded Distant Viewing of Diagrams: Insights from Two Multimodal Corpora.” Digital Scholarship in the Humanities 37 (2): 405–25.\n\n\nKing, Ryan C, Vishnu Bharani, Kunal Shah, Yee Hui Yeo, and Jamil S Samaan. 2024. “GPT-4V Passes the BLS and ACLS Examinations: An Analysis of GPT-4V’s Image Recognition Capabilities.” Resuscitation 195.\n\n\nKlinkert, Ivo, Liam A McDonnell, Stefan L Luxembourg, AF Maarten Altelaar, Erika R Amstalden, Sander R Piersma, and Ron Heeren. 2007. “Tools and Strategies for Visualization of Large Image Data Sets in High-Resolution Imaging Mass Spectrometry.” Review of Scientific Instruments 78 (5).\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLee, Benjamin Charles Germain. 2023. “The ‘Collections as ML Data’ Checklist for Machine Learning and Cultural Heritage.” Journal of the Association for Information Science and Technology.\n\n\nLei, Yiming, Zilong Li, Yangyang Li, Junping Zhang, and Hongming Shan. 2024. “LICO: Explainable Models with Language-Image Consistency.” Advances in Neural Information Processing Systems 36.\n\n\nLiu, Fang, Mohan Zhang, Baoying Zheng, Shenglan Cui, Wentao Ma, and Zhixiong Liu. 2023. “Feature Fusion via Multi-Target Learning for Ancient Artwork Captioning.” Information Fusion 97: 101811.\n\n\nMcInnes, Leland, John Healy, and James Melville. 2018. “UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.” arXiv Preprint arXiv:1802.03426.\n\n\nMeinecke, Christofer, Chris Hall, and Stefan Jänicke. 2022. “Towards Enhancing Virtual Museums by Contextualizing Art Through Interactive Visualizations.” ACM Journal on Computing and Cultural Heritage 15 (4): 1–26.\n\n\nMoreux, Jean-Philippe. 2023. “Intelligence Artificielle Et Indexation Des Images.” In Journées Du Patrimoine écrit:“l’image Aura-t-Elle Le Dernier Mot? Regards Croisés Sur Les Collections Iconographiques En Bibliothèques”.\n\n\nMorse, Christopher, Blandine Landau, Carine Lallemand, Lars Wieneke, and Vincent Koenig. 2022. “From #Museumathome to #Athomeatthemuseum: Digital Museums and Dialogical Engagement Beyond the COVID-19 Pandemic.” ACM Journal on Computing and Cultural Heritage (JOCCH) 15 (2): 1–29.\n\n\nMurtagh, Fionn, and Pierre Legendre. 2014. “Ward’s Hierarchical Agglomerative Clustering Method: Which Algorithms Implement Ward’s Criterion?” Journal of Classification 31: 274–95.\n\n\nPaiss, Roni, Hila Chefer, and Lior Wolf. 2022. “No Token Left Behind: Explainability-Aided Image Classification and Generation.” In European Conference on Computer Vision, 334–50. Springer.\n\n\nPetukhova, Alina, Joao P Matos-Carvalho, and Nuno Fachada. 2024. “Text Clustering with LLM Embeddings.” arXiv Preprint arXiv:2403.15112.\n\n\nPuscasiu, Adela, Alexandra Fanca, Dan-Ioan Gota, and Honoriu Valean. 2020. “Automated Image Captioning.” In 2020 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR), 1–6. IEEE.\n\n\nQi, Zhongang, Saeed Khorram, and Li Fuxin. 2021. “Embedding Deep Networks into Visual Explanations.” Artificial Intelligence 292: 103435.\n\n\nQi, Zhongang, and Fuxin Li. 2017. “Learning Explainable Embeddings for Deep Networks.” In NIPS Workshop on Interpretable Machine Learning. Vol. 31.\n\n\nRadford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. “Learning Transferable Visual Models from Natural Language Supervision.” In International Conference on Machine Learning, 8748–63. PMLR.\n\n\nRinaldi, Antonio M, Cristiano Russo, and Cristian Tommasino. 2023. “Automatic Image Captioning Combining Natural Language Processing and Deep Neural Networks.” Results in Engineering 18: 101107.\n\n\nSheng, Shurong, and Marie-Francine Moens. 2019. “Generating Captions for Images of Ancient Artworks.” In Proceedings of the 27th ACM International Conference on Multimedia, 2478–86.\n\n\nSiddiqui, Nabeel. 2024. “Cutting the Frame: An in-Depth Look at the Hitchcock Computer Vision Dataset.” Journal of Open Humanities Data 10 (1).\n\n\nSmits, Thomas, and Melvin Wevers. 2023. “A Multimodal Turn in Digital Humanities. Using Contrastive Machine Learning Models to Explore, Enrich, and Analyze Digital Visual Historical Collections.” Digital Scholarship in the Humanities 38 (3): 1267–80.\n\n\nStefanowitsch, Anatol. 2020. Corpus Linguistics: A Guide to the Methodology. Language Science Press.\n\n\nStraka, Milan, Jan Hajic, and Jana Straková. 2016. “UDPipe: Trainable Pipeline for Processing CoNLL-u Files Performing Tokenization, Morphological Analysis, Pos Tagging and Parsing.” In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16), 4290–97.\n\n\nTan, Mingxing, and Quoc Le. 2019. “EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.” In International Conference on Machine Learning, 6105–14. PMLR.\n\n\nVerma, Akash, Arun Kumar Yadav, Mohit Kumar, and Divakar Yadav. 2024. “Automatic Image Caption Generation Using Deep Learning.” Multimedia Tools and Applications 83 (2): 5309–25.\n\n\nWevers, Melvin, and Thomas Smits. 2020. “The Visual Digital Turn: Using Neural Networks to Study Historical Images.” Digital Scholarship in the Humanities 35 (1): 194–207.\n\n\nWhitelaw, Mitchell. 2015. “Generous Interfaces for Digital Cultural Collections.” Digital Humanities Quarterly 9 (1): 1–16.\n\n\nWindhager, Florian, Paolo Federico, Günther Schreder, Katrin Glinka, Marian Dörk, Silvia Miksch, and Eva Mayr. 2018. “Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges.” IEEE Transactions on Visualization and Computer Graphics 25 (6): 2311–30.\n\n\nWu, Wenhao, Huanjin Yao, Mengxi Zhang, Yuxin Song, Wanli Ouyang, and Jingdong Wang. 2023. “GPT4Vis: What Can GPT-4 Do for Zero-Shot Visual Recognition?” arXiv Preprint arXiv:2311.15732.\n\n\nYe, Yilin, Rong Huang, and Wei Zeng. 2022. “VISAtlas: An Image-Based Exploration and Query System for Large Visualization Collections via Neural Image Embedding.” IEEE Transactions on Visualization and Computer Graphics.\n\n\nYin, Shukang, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. 2023. “A Survey on Multimodal Large Language Models.” arXiv Preprint arXiv:2306.13549.\n\n\nYou, Haoxuan, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, Zirui Wang, Liangliang Cao, Shih-Fu Chang, and Yinfei Yang. 2023. “Ferret: Refer and Ground Anything Anywhere at Any Granularity.” arXiv Preprint arXiv:2310.07704.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "00_image.html",
    "href": "00_image.html",
    "title": "Images",
    "section": "",
    "text": "Some text",
    "crumbs": [
      "Images"
    ]
  },
  {
    "objectID": "2.1_classification.html",
    "href": "2.1_classification.html",
    "title": "2.1 Image Classification",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Images",
      "2.1 Image Classification"
    ]
  },
  {
    "objectID": "2.2_object.html",
    "href": "2.2_object.html",
    "title": "2.2 Object Detection",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Images",
      "2.2 Object Detection"
    ]
  },
  {
    "objectID": "2.3_depth.html",
    "href": "2.3_depth.html",
    "title": "2.3 Depth Estimation",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Images",
      "2.3 Depth Estimation"
    ]
  },
  {
    "objectID": "2.4_segment.html",
    "href": "2.4_segment.html",
    "title": "2.4 Image Segmentation",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Images",
      "2.4 Image Segmentation"
    ]
  },
  {
    "objectID": "2.5_embed.html",
    "href": "2.5_embed.html",
    "title": "2.5 Embedding",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Images",
      "2.5 Embedding"
    ]
  },
  {
    "objectID": "00_video.html",
    "href": "00_video.html",
    "title": "Video + Audio",
    "section": "",
    "text": "Some text",
    "crumbs": [
      "Video + Audio"
    ]
  },
  {
    "objectID": "3.1_shot.html",
    "href": "3.1_shot.html",
    "title": "3.1 Shot Boundary",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Video + Audio",
      "3.1 Shot Boundary"
    ]
  },
  {
    "objectID": "3.2_transcription.html",
    "href": "3.2_transcription.html",
    "title": "3.2 Transcription",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Video + Audio",
      "3.2 Transcription"
    ]
  },
  {
    "objectID": "3.3_diarization.html",
    "href": "3.3_diarization.html",
    "title": "3.3 Diarization",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Video + Audio",
      "3.3 Diarization"
    ]
  },
  {
    "objectID": "00_text.html",
    "href": "00_text.html",
    "title": "Text",
    "section": "",
    "text": "Some text",
    "crumbs": [
      "Text"
    ]
  },
  {
    "objectID": "4.1_sentiment.html",
    "href": "4.1_sentiment.html",
    "title": "4.1 Sentiment Analysis",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Text",
      "4.1 Sentiment Analysis"
    ]
  },
  {
    "objectID": "4.2_review.html",
    "href": "4.2_review.html",
    "title": "4.2 Review Prediction",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Text",
      "4.2 Review Prediction"
    ]
  },
  {
    "objectID": "4.3_comment.html",
    "href": "4.3_comment.html",
    "title": "4.3 Comment Labels",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Text",
      "4.3 Comment Labels"
    ]
  },
  {
    "objectID": "4.4_mask.html",
    "href": "4.4_mask.html",
    "title": "4.4 Text Mask",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Text",
      "4.4 Text Mask"
    ]
  },
  {
    "objectID": "00_multimodal.html",
    "href": "00_multimodal.html",
    "title": "Multimodal",
    "section": "",
    "text": "Some text",
    "crumbs": [
      "Multimodal"
    ]
  },
  {
    "objectID": "5.1_zeroshot.html",
    "href": "5.1_zeroshot.html",
    "title": "5.1 Zero-Shot Model",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Multimodal",
      "5.1 Zero-Shot Model"
    ]
  },
  {
    "objectID": "5.2_caption.html",
    "href": "5.2_caption.html",
    "title": "5.2 Image Caption",
    "section": "",
    "text": "Hello!",
    "crumbs": [
      "Multimodal",
      "5.2 Image Caption"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Achiam, Josh, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,\nFlorencia Leoni Aleman, Diogo Almeida, et al. 2023.\n“GPT-4 Technical Report.” arXiv Preprint\narXiv:2303.08774.\n\n\nAdnan, Myasar Mundher, Mohd Shafry Mohd Rahim, Amjad Rehman, Zahid\nMehmood, Tanzila Saba, and Rizwan Ali Naqvi. 2021. “Automatic\nImage Annotation Based on Deep Learning Models: A Systematic Review and\nFuture Challenges.” IEEE Access 9: 50253–64.\n\n\nAfzal, Shehzad, Sohaib Ghani, Mohamad Mazen Hittawe, Sheikh Faisal\nRashid, Omar M Knio, Markus Hadwiger, and Ibrahim Hoteit. 2023.\n“Visualization and Visual Analytics Approaches for Image and Video\nDatasets: A Survey.” ACM Transactions on Interactive\nIntelligent Systems 13 (1): 1–41.\n\n\nAnitha Kumari, K, C Mouneeshwari, RB Udhaya, and R Jasmitha. 2020.\n“Automated Image Captioning for flickr8k Dataset.” In Proceedings of\nInternational Conference on Artificial Intelligence, Smart Grid and\nSmart City Applications: AISGSC 2019, 679–87. Springer.\n\n\nArchives, United States National. n.d. “DOCUMERICA:\nThe Environmental Protection Agency’s Program to Photographically\nDocument Subjects of Environmental Concern, 1972–1977.” https://catalog.archives.gov/id/542493.\n\n\nArnold, Taylor, and Lauren Tilton. 2019. “Distant Viewing:\nAnalyzing Large Visual Corpora.” Digital Scholarship in the\nHumanities 34 (Supplement_1): i3–16.\n\n\n———. 2020. “Distant Viewing Toolkit: A Python Package for the\nAnalysis of Visual Culture.” Journal of Open Source\nSoftware 5 (45): 1800.\n\n\n———. 2023. Distant Viewing: Computational Exploration of Digital\nImages. MIT Press.\n\n\nChen, Hailin, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut,\nRuochen Zhao, Caiming Xiong, and Shafiq Joty. 2023. “ChatGPT’s\nOne-Year Anniversary: Are Open-Source Large Language Models Catching\nUp?” arXiv Preprint arXiv:2311.16989.\n\n\nColeman, Catherine Nicole. 2020. “Managing Bias When Library\nCollections Become Data.” International Journal of\nLibrarianship 5 (1): 8–19.\n\n\nCuntz, Alexander, Paul J Heald, and Matthias Sahli. 2023.\n“Digitization and Availability of Artworks in Online Museum\nCollections.” World Intellectual Property Organization (WIPO)\nEconomic Research Working Paper Series, no. 75.\n\n\nDeal, Laura. 2015. “Visualizing Digital Collections.”\nTechnical Services Quarterly 32 (1): 14–34.\n\n\nDemiralp, Çagatay, Carlos E Scheidegger, Gordon L Kindlmann, David H\nLaidlaw, and Jeffrey Heer. 2014. “Visual Embedding: A Model for\nVisualization.” IEEE Computer Graphics and Applications\n34 (1): 10–15.\n\n\nDi Lenardo, Isabella, Benoı̂t Laurent Auguste Seguin, and Frédéric\nKaplan. 2016. “Visual Patterns Discovery in Large Databases of\nPaintings.” In Digital Humanities 2016.\n\n\nDı́az-Rodrı́guez, Natalia, and Galena Pisoni. 2020. “Accessible\nCultural Heritage Through Explainable Artificial Intelligence.”\nIn Adjunct Publication of the 28th ACM Conference on User Modeling,\nAdaptation and Personalization, 317–24.\n\n\nFlueckiger, Barbara, and Gaudenz Halter. 2020. “Methods and\nAdvanced Tools for the Analysis of Film Colors in Digital\nHumanities.” DHQ: Digital Humanities Quarterly 14 (4).\n\n\nFraser, Kathleen C, Svetlana Kiritchenko, and Isar Nejadgholi. 2023.\n“A Friendly Face: Do Text-to-Image Systems Rely on Stereotypes\nWhen the Input Is Under-Specified?” arXiv Preprint\narXiv:2302.07159.\n\n\nGefen, Alexandre, Léa Saint-Raymond, and Tommaso Venturini. 2021.\n“AI for Digital Humanities and Computational Social\nSciences.” Reflections on Artificial Intelligence for\nHumanity, 191–202.\n\n\nHiippala, Tuomo, and John A Bateman. 2022. “Semiotically-Grounded\nDistant Viewing of Diagrams: Insights from Two Multimodal\nCorpora.” Digital Scholarship in the Humanities 37 (2):\n405–25.\n\n\nKing, Ryan C, Vishnu Bharani, Kunal Shah, Yee Hui Yeo, and Jamil S\nSamaan. 2024. “GPT-4V Passes the\nBLS and ACLS Examinations: An Analysis of\nGPT-4V’s Image Recognition Capabilities.”\nResuscitation 195.\n\n\nKlinkert, Ivo, Liam A McDonnell, Stefan L Luxembourg, AF Maarten\nAltelaar, Erika R Amstalden, Sander R Piersma, and Ron Heeren. 2007.\n“Tools and Strategies for Visualization of Large Image Data Sets\nin High-Resolution Imaging Mass Spectrometry.” Review of\nScientific Instruments 78 (5).\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLee, Benjamin Charles Germain. 2023. “The ‘Collections as\nML Data’ Checklist for Machine Learning and Cultural\nHeritage.” Journal of the Association for Information Science\nand Technology.\n\n\nLei, Yiming, Zilong Li, Yangyang Li, Junping Zhang, and Hongming Shan.\n2024. “LICO: Explainable Models with Language-Image\nConsistency.” Advances in Neural Information Processing\nSystems 36.\n\n\nLiu, Fang, Mohan Zhang, Baoying Zheng, Shenglan Cui, Wentao Ma, and\nZhixiong Liu. 2023. “Feature Fusion via Multi-Target Learning for\nAncient Artwork Captioning.” Information Fusion 97:\n101811.\n\n\nMcInnes, Leland, John Healy, and James Melville. 2018.\n“UMAP: Uniform Manifold Approximation and Projection\nfor Dimension Reduction.” arXiv Preprint\narXiv:1802.03426.\n\n\nMeinecke, Christofer, Chris Hall, and Stefan Jänicke. 2022.\n“Towards Enhancing Virtual Museums by Contextualizing Art Through\nInteractive Visualizations.” ACM Journal on\nComputing and Cultural Heritage 15 (4): 1–26.\n\n\nMoreux, Jean-Philippe. 2023. “Intelligence Artificielle Et\nIndexation Des Images.” In Journées Du\nPatrimoine écrit:“l’image Aura-t-Elle\nLe Dernier Mot? Regards Croisés Sur Les Collections\nIconographiques En Bibliothèques”.\n\n\nMorse, Christopher, Blandine Landau, Carine Lallemand, Lars Wieneke, and\nVincent Koenig. 2022. “From #Museumathome to #Athomeatthemuseum:\nDigital Museums and Dialogical Engagement Beyond the\nCOVID-19 Pandemic.” ACM Journal on Computing and\nCultural Heritage (JOCCH) 15 (2): 1–29.\n\n\nMurtagh, Fionn, and Pierre Legendre. 2014. “Ward’s Hierarchical\nAgglomerative Clustering Method: Which Algorithms Implement Ward’s\nCriterion?” Journal of Classification 31: 274–95.\n\n\nPaiss, Roni, Hila Chefer, and Lior Wolf. 2022. “No Token Left\nBehind: Explainability-Aided Image Classification and\nGeneration.” In European Conference on Computer Vision,\n334–50. Springer.\n\n\nPetukhova, Alina, Joao P Matos-Carvalho, and Nuno Fachada. 2024.\n“Text Clustering with LLM Embeddings.”\narXiv Preprint arXiv:2403.15112.\n\n\nPuscasiu, Adela, Alexandra Fanca, Dan-Ioan Gota, and Honoriu Valean.\n2020. “Automated Image Captioning.” In 2020 IEEE\nInternational Conference on Automation, Quality and Testing, Robotics\n(AQTR), 1–6. IEEE.\n\n\nQi, Zhongang, Saeed Khorram, and Li Fuxin. 2021. “Embedding Deep\nNetworks into Visual Explanations.” Artificial\nIntelligence 292: 103435.\n\n\nQi, Zhongang, and Fuxin Li. 2017. “Learning Explainable Embeddings\nfor Deep Networks.” In NIPS Workshop on Interpretable Machine\nLearning. Vol. 31.\n\n\nRadford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,\nSandhini Agarwal, Girish Sastry, et al. 2021. “Learning\nTransferable Visual Models from Natural Language Supervision.” In\nInternational Conference on Machine Learning, 8748–63. PMLR.\n\n\nRinaldi, Antonio M, Cristiano Russo, and Cristian Tommasino. 2023.\n“Automatic Image Captioning Combining Natural Language Processing\nand Deep Neural Networks.” Results in Engineering 18:\n101107.\n\n\nSheng, Shurong, and Marie-Francine Moens. 2019. “Generating\nCaptions for Images of Ancient Artworks.” In Proceedings of\nthe 27th ACM International Conference on Multimedia, 2478–86.\n\n\nSiddiqui, Nabeel. 2024. “Cutting the Frame: An in-Depth Look at\nthe Hitchcock Computer Vision Dataset.” Journal of Open\nHumanities Data 10 (1).\n\n\nSmits, Thomas, and Melvin Wevers. 2023. “A Multimodal Turn in\nDigital Humanities. Using Contrastive Machine Learning Models to\nExplore, Enrich, and Analyze Digital Visual Historical\nCollections.” Digital Scholarship in the Humanities 38\n(3): 1267–80.\n\n\nStefanowitsch, Anatol. 2020. Corpus Linguistics: A Guide to the\nMethodology. Language Science Press.\n\n\nStraka, Milan, Jan Hajic, and Jana Straková. 2016.\n“UDPipe: Trainable Pipeline for Processing CoNLL-u\nFiles Performing Tokenization, Morphological Analysis, Pos Tagging and\nParsing.” In Proceedings of the Tenth International\nConference on Language Resources and Evaluation (LREC’16), 4290–97.\n\n\nTan, Mingxing, and Quoc Le. 2019. “EfficientNet:\nRethinking Model Scaling for Convolutional Neural Networks.” In\nInternational Conference on Machine Learning, 6105–14. PMLR.\n\n\nVerma, Akash, Arun Kumar Yadav, Mohit Kumar, and Divakar Yadav. 2024.\n“Automatic Image Caption Generation Using Deep Learning.”\nMultimedia Tools and Applications 83 (2): 5309–25.\n\n\nWevers, Melvin, and Thomas Smits. 2020. “The Visual Digital Turn:\nUsing Neural Networks to Study Historical Images.” Digital\nScholarship in the Humanities 35 (1): 194–207.\n\n\nWhitelaw, Mitchell. 2015. “Generous Interfaces for Digital\nCultural Collections.” Digital Humanities Quarterly 9\n(1): 1–16.\n\n\nWindhager, Florian, Paolo Federico, Günther Schreder, Katrin Glinka,\nMarian Dörk, Silvia Miksch, and Eva Mayr. 2018. “Visualization of\nCultural Heritage Collection Data: State of the Art and Future\nChallenges.” IEEE Transactions on Visualization and Computer\nGraphics 25 (6): 2311–30.\n\n\nWu, Wenhao, Huanjin Yao, Mengxi Zhang, Yuxin Song, Wanli Ouyang, and\nJingdong Wang. 2023. “GPT4Vis: What Can\nGPT-4 Do for Zero-Shot Visual Recognition?”\narXiv Preprint arXiv:2311.15732.\n\n\nYe, Yilin, Rong Huang, and Wei Zeng. 2022. “VISAtlas:\nAn Image-Based Exploration and Query System for Large Visualization\nCollections via Neural Image Embedding.” IEEE Transactions on\nVisualization and Computer Graphics.\n\n\nYin, Shukang, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and\nEnhong Chen. 2023. “A Survey on Multimodal Large Language\nModels.” arXiv Preprint arXiv:2306.13549.\n\n\nYou, Haoxuan, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, Zirui\nWang, Liangliang Cao, Shih-Fu Chang, and Yinfei Yang. 2023.\n“Ferret: Refer and Ground Anything Anywhere at Any\nGranularity.” arXiv Preprint arXiv:2310.07704.",
    "crumbs": [
      "References"
    ]
  }
]